{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6da926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0460597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from interface import PolyDisVAE\n",
    "from base_model import converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ffa03",
   "metadata": {},
   "source": [
    "### Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22f5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = 'features'\n",
    "MODEL_PATH = 'model_param/polydis-v1.pt'\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a36a49c-7e48-4e6e-b36e-8ac55af8da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DisentangleVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87f2684f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolyDisVAE(\n",
       "  (chd_encoder): ChordEncoder(\n",
       "    (gru): GRU(36, 1024, batch_first=True, bidirectional=True)\n",
       "    (linear_mu): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (linear_var): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       "  (txt_encoder): TextureEncoder(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(1, 10, kernel_size=(4, 12), stride=(4, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (fc1): Linear(in_features=290, out_features=1000, bias=True)\n",
       "    (fc2): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (gru): GRU(256, 1024, batch_first=True, bidirectional=True)\n",
       "    (linear_mu): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (linear_var): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       "  (pnotree_decoder): PianoTreeDecoder(\n",
       "    (note_embedding): Linear(in_features=135, out_features=128, bias=True)\n",
       "    (z2dec_hid_linear): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (z2dec_in_linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dec_notes_emb_gru): GRU(128, 128, batch_first=True, bidirectional=True)\n",
       "    (dec_time_gru): GRU(512, 1024, batch_first=True)\n",
       "    (dec_time_to_notes_hid): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dec_notes_gru): GRU(1152, 512, batch_first=True)\n",
       "    (pitch_out_linear): Linear(in_features=512, out_features=130, bias=True)\n",
       "    (dec_dur_gru): GRU(5, 64, batch_first=True)\n",
       "    (dur_hid_linear): Linear(in_features=642, out_features=64, bias=True)\n",
       "    (dur_out_linear): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (chd_decoder): ChordDecoder(\n",
       "    (z2dec_hid): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (z2dec_in): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (gru): GRU(292, 512, batch_first=True)\n",
       "    (root_out): Linear(in_features=512, out_features=12, bias=True)\n",
       "    (chroma_out): Linear(in_features=512, out_features=24, bias=True)\n",
       "    (bass_out): Linear(in_features=512, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PolyDisVAE.init_model(device=DEVICE)\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model.load_model(MODEL_PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6e7dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator(feature_dir, batch_size):\n",
    "    files = sorted([f for f in os.listdir(feature_dir) if f.endswith('.npz')])\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i+batch_size]\n",
    "        piano_rolls = []\n",
    "        chords = []\n",
    "        for bf in batch_files:\n",
    "            data = np.load(os.path.join(feature_dir, bf))\n",
    "            piano_rolls.append(data['piano_roll'])\n",
    "            chords.append(data['chord'])\n",
    "        yield np.stack(piano_rolls), np.stack(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6581087",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolyDisVAE' object has no attribute 'loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m x_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m(x_t, chd_t, pr_t)\n\u001b[1;32m     13\u001b[0m     dist_chd, dist_txt \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minference_encode(pr_t, chd_t)\n\u001b[1;32m     14\u001b[0m latents_chd\u001b[38;5;241m.\u001b[39mappend(dist_chd\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolyDisVAE' object has no attribute 'loss'"
     ]
    }
   ],
   "source": [
    "latents_txt = []\n",
    "latents_chd = []\n",
    "recon_losses = []\n",
    "\n",
    "for pr_batch, chd_batch in batch_iterator(FEATURE_DIR, BATCH_SIZE):\n",
    "    x = np.stack([converter.target_to_3dtarget(pr) for pr in pr_batch])\n",
    "    pr_t = torch.tensor(pr_batch, dtype=torch.float32, device=DEVICE)\n",
    "    chd_t = torch.tensor(chd_batch, dtype=torch.float32, device=DEVICE)\n",
    "    x_t = torch.tensor(x, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = DisentangleVAE.loss(x_t, chd_t, pr_t)\n",
    "        dist_chd, dist_txt = model.inference_encode(pr_t, chd_t)\n",
    "    latents_chd.append(dist_chd.mean.cpu().numpy())\n",
    "    latents_txt.append(dist_txt.mean.cpu().numpy())\n",
    "    recon_losses.append(out[1].cpu().numpy())\n",
    "\n",
    "latents_txt = np.concatenate(latents_txt)\n",
    "latents_chd = np.concatenate(latents_chd)\n",
    "recon_losses = np.concatenate(recon_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "txt_2d = reducer.fit_transform(latents_txt)\n",
    "chd_2d = reducer.fit_transform(latents_chd)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "sc0 = axs[0].scatter(txt_2d[:,0], txt_2d[:,1], c=recon_losses, cmap='viridis')\n",
    "axs[0].set_title('Textura (UMAP)')\n",
    "plt.colorbar(sc0, ax=axs[0])\n",
    "sc1 = axs[1].scatter(chd_2d[:,0], chd_2d[:,1], c=recon_losses, cmap='viridis')\n",
    "axs[1].set_title('Acorde (UMAP)')\n",
    "plt.colorbar(sc1, ax=axs[1])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
