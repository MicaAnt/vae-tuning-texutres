{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6da926a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0460597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "from interface import PolyDisVAE\n",
    "from base_model import converter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70ffa03",
   "metadata": {},
   "source": [
    "### Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22f5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_DIR = 'features'\n",
    "MODEL_PATH = 'model_param/polydis-v1.pt'\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a36a49c-7e48-4e6e-b36e-8ac55af8da1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DisentangleVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87f2684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/vae-tuning-texutres/interface.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dic = torch.load(model_path, map_location=self.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PolyDisVAE(\n",
       "  (chd_encoder): ChordEncoder(\n",
       "    (gru): GRU(36, 1024, batch_first=True, bidirectional=True)\n",
       "    (linear_mu): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (linear_var): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       "  (txt_encoder): TextureEncoder(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(1, 10, kernel_size=(4, 12), stride=(4, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (fc1): Linear(in_features=290, out_features=1000, bias=True)\n",
       "    (fc2): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (gru): GRU(256, 1024, batch_first=True, bidirectional=True)\n",
       "    (linear_mu): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (linear_var): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       "  (pnotree_decoder): PianoTreeDecoder(\n",
       "    (note_embedding): Linear(in_features=135, out_features=128, bias=True)\n",
       "    (z2dec_hid_linear): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (z2dec_in_linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dec_notes_emb_gru): GRU(128, 128, batch_first=True, bidirectional=True)\n",
       "    (dec_time_gru): GRU(512, 1024, batch_first=True)\n",
       "    (dec_time_to_notes_hid): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dec_notes_gru): GRU(1152, 512, batch_first=True)\n",
       "    (pitch_out_linear): Linear(in_features=512, out_features=130, bias=True)\n",
       "    (dec_dur_gru): GRU(5, 64, batch_first=True)\n",
       "    (dur_hid_linear): Linear(in_features=642, out_features=64, bias=True)\n",
       "    (dur_out_linear): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (chd_decoder): ChordDecoder(\n",
       "    (z2dec_hid): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (z2dec_in): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (gru): GRU(292, 512, batch_first=True)\n",
       "    (root_out): Linear(in_features=512, out_features=12, bias=True)\n",
       "    (chroma_out): Linear(in_features=512, out_features=24, bias=True)\n",
       "    (bass_out): Linear(in_features=512, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PolyDisVAE.init_model(device=DEVICE)\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model.load_model(MODEL_PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6e7dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iterator(feature_dir, batch_size):\n",
    "    files = sorted([f for f in os.listdir(feature_dir) if f.endswith('.npz')])\n",
    "    for i in range(0, len(files), batch_size):\n",
    "        batch_files = files[i:i+batch_size]\n",
    "        piano_rolls = []\n",
    "        chords = []\n",
    "        for bf in batch_files:\n",
    "            data = np.load(os.path.join(feature_dir, bf))\n",
    "            piano_rolls.append(data['piano_roll'])\n",
    "            chords.append(data['chord'])\n",
    "        yield np.stack(piano_rolls), np.stack(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6581087",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolyDisVAE' object has no attribute 'run'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m x_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 16\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mDisentangleVAE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchd_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpr_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     dist_chd, dist_txt \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minference_encode(pr_t, chd_t)\n\u001b[1;32m     18\u001b[0m latents_chd\u001b[38;5;241m.\u001b[39mappend(dist_chd\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/workspace/vae-tuning-texutres/./base_model/model.py:94\u001b[0m, in \u001b[0;36mDisentangleVAE.loss\u001b[0;34m(self, x, c, pr_mat, tfr1, tfr2, tfr3, beta, weights)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, c, pr_mat, tfr1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, tfr2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, tfr3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m,\n\u001b[1;32m     93\u001b[0m          beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, weights\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)):\n\u001b[0;32m---> 94\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m(x, c, pr_mat, tfr1, tfr2, tfr3)\n\u001b[1;32m     95\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(x, c, \u001b[38;5;241m*\u001b[39moutputs, beta, weights)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PolyDisVAE' object has no attribute 'run'"
     ]
    }
   ],
   "source": [
    "# após carregar o modelo\n",
    "model.decoder = model.pnotree_decoder\n",
    "model.rhy_encoder = model.txt_encoder\n",
    "\n",
    "latents_txt = []\n",
    "latents_chd = []\n",
    "recon_losses = []\n",
    "\n",
    "for pr_batch, chd_batch in batch_iterator(FEATURE_DIR, BATCH_SIZE):\n",
    "    x = np.stack([converter.target_to_3dtarget(pr) for pr in pr_batch])\n",
    "    pr_t = torch.tensor(pr_batch, dtype=torch.float32, device=DEVICE)\n",
    "    chd_t = torch.tensor(chd_batch, dtype=torch.float32, device=DEVICE)\n",
    "    x_t = torch.tensor(x, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = DisentangleVAE.loss(model, x_t, chd_t, pr_t)\n",
    "        dist_chd, dist_txt = model.inference_encode(pr_t, chd_t)\n",
    "    latents_chd.append(dist_chd.mean.cpu().numpy())\n",
    "    latents_txt.append(dist_txt.mean.cpu().numpy())\n",
    "    recon_losses.append(out[1].cpu().numpy())\n",
    "\n",
    "latents_txt = np.concatenate(latents_txt)\n",
    "latents_chd = np.concatenate(latents_chd)\n",
    "recon_losses = np.concatenate(recon_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3484043c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "txt_2d = reducer.fit_transform(latents_txt)\n",
    "chd_2d = reducer.fit_transform(latents_chd)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12,5))\n",
    "sc0 = axs[0].scatter(txt_2d[:,0], txt_2d[:,1], c=recon_losses, cmap='viridis')\n",
    "axs[0].set_title('Textura (UMAP)')\n",
    "plt.colorbar(sc0, ax=axs[0])\n",
    "sc1 = axs[1].scatter(chd_2d[:,0], chd_2d[:,1], c=recon_losses, cmap='viridis')\n",
    "axs[1].set_title('Acorde (UMAP)')\n",
    "plt.colorbar(sc1, ax=axs[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4434ece4-5fef-45fe-a74c-a3c32eb25e14",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "shape mismatch: indexing tensors could not be broadcast together with shapes [32768], [22528]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m x_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(x, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mDEVICE)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 23\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchd_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpr_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     dist_chd, dist_txt \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minference_encode(pr_t, chd_t)\n\u001b[1;32m     25\u001b[0m latents_chd\u001b[38;5;241m.\u001b[39mappend(dist_chd\u001b[38;5;241m.\u001b[39mmean\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/workspace/vae-tuning-texutres/./base_model/model.py:94\u001b[0m, in \u001b[0;36mDisentangleVAE.loss\u001b[0;34m(self, x, c, pr_mat, tfr1, tfr2, tfr3, beta, weights)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mloss\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, c, pr_mat, tfr1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, tfr2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, tfr3\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m,\n\u001b[1;32m     93\u001b[0m          beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, weights\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m)):\n\u001b[0;32m---> 94\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpr_mat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfr1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfr2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfr3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_function(x, c, \u001b[38;5;241m*\u001b[39moutputs, beta, weights)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/workspace/vae-tuning-texutres/./base_model/model.py:43\u001b[0m, in \u001b[0;36mDisentangleVAE.run\u001b[0;34m(self, x, c, pr_mat, tfr1, tfr2, tfr3, confuse)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, c, pr_mat, tfr1, tfr2, tfr3, confuse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 43\u001b[0m     embedded_x, lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_x\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# cc = self.get_chroma(pr_mat)\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     dist_chd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchd_encoder(c)\n",
      "File \u001b[0;32m/workspace/vae-tuning-texutres/dl_modules/pnotree_decoder.py:324\u001b[0m, in \u001b[0;36mPianoTreeDecoder.emb_x\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21memb_x\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    323\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_len_index_tensor(x)\n\u001b[0;32m--> 324\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_tensor_to_multihot_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnote_embedding(x)\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded, lengths\n",
      "File \u001b[0;32m/workspace/vae-tuning-texutres/dl_modules/pnotree_decoder.py:100\u001b[0m, in \u001b[0;36mPianoTreeDecoder.index_tensor_to_multihot_tensor\u001b[0;34m(self, ind_x)\u001b[0m\n\u001b[1;32m     94\u001b[0m dur_part \u001b[38;5;241m=\u001b[39m ind_x[:, :, :, \u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     95\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\n\u001b[1;32m     96\u001b[0m     [ind_x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_step \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_simu_note,\n\u001b[1;32m     97\u001b[0m      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpitch_range \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     98\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 100\u001b[0m \u001b[43mout\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mind_x\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\n\u001b[1;32m    101\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_simu_note, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpitch_range \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    102\u001b[0m out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([out[:, :, :, \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpitch_range], dur_part],\n\u001b[1;32m    103\u001b[0m                 dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: shape mismatch: indexing tensors could not be broadcast together with shapes [32768], [22528]"
     ]
    }
   ],
   "source": [
    "# após carregar o modelo\n",
    "model.decoder = model.pnotree_decoder\n",
    "model.rhy_encoder = model.txt_encoder\n",
    "\n",
    "# attach functions of DisentangleVAE to this instance\n",
    "model.run = DisentangleVAE.run.__get__(model, type(model))\n",
    "model.loss_function = DisentangleVAE.loss_function.__get__(model, type(model))\n",
    "model.chord_loss = DisentangleVAE.chord_loss.__get__(model, type(model))\n",
    "model.kl_loss = DisentangleVAE.kl_loss.__get__(model, type(model))\n",
    "model.loss = DisentangleVAE.loss.__get__(model, type(model))\n",
    "\n",
    "latents_txt = []\n",
    "latents_chd = []\n",
    "recon_losses = []\n",
    "\n",
    "for pr_batch, chd_batch in batch_iterator(FEATURE_DIR, BATCH_SIZE):\n",
    "    x = np.stack([converter.target_to_3dtarget(pr) for pr in pr_batch])\n",
    "    pr_t = torch.tensor(pr_batch, dtype=torch.float32, device=DEVICE)\n",
    "    chd_t = torch.tensor(chd_batch, dtype=torch.float32, device=DEVICE)\n",
    "    x_t = torch.tensor(x, dtype=torch.long, device=DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.loss(x_t, chd_t, pr_t)\n",
    "        dist_chd, dist_txt = model.inference_encode(pr_t, chd_t)\n",
    "    latents_chd.append(dist_chd.mean.cpu().numpy())\n",
    "    latents_txt.append(dist_txt.mean.cpu().numpy())\n",
    "    recon_losses.append(out[1].cpu().numpy())\n",
    "\n",
    "latents_txt = np.concatenate(latents_txt)\n",
    "latents_chd = np.concatenate(latents_chd)\n",
    "recon_losses = np.concatenate(recon_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53f494-b23c-4324-96d8-2de570c1aed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
