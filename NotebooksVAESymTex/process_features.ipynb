{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be2b591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./base_model')\n",
    "from interface import PolyDisVAE\n",
    "import torch, os, numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1008930b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/vae-tuning-texutres/interface.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dic = torch.load(model_path, map_location=self.device)\n"
     ]
    }
   ],
   "source": [
    "# initialize the VAE model\n",
    "polydis_model = PolyDisVAE.init_model()\n",
    "polydis_model.load_model('./model_param/polydis-v1.pt')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89bebd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62034"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare feature files and output location\n",
    "from glob import glob\n",
    "feature_dir = './features'\n",
    "latent_dir = './latent_features'\n",
    "os.makedirs(latent_dir, exist_ok=True)\n",
    "feature_files = sorted(glob(os.path.join(feature_dir, '*.npz')))\n",
    "len(feature_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74058ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_block(files):\n",
    "    z_chds = []\n",
    "    z_txts = []\n",
    "    for path in files:\n",
    "        with np.load(path) as feat:\n",
    "            pr = feat['piano_roll']\n",
    "            chd = feat['chord']\n",
    "        c = torch.from_numpy(chd).float().to(device).unsqueeze(0)\n",
    "        pr = torch.from_numpy(pr).float().to(device).unsqueeze(0)\n",
    "        z_chd = polydis_model.chd_encode(c)\n",
    "        z_txt = polydis_model.txt_encode(pr)\n",
    "        z_chds.append(z_chd.cpu().numpy())\n",
    "        z_txts.append(z_txt.cpu().numpy())\n",
    "    return np.concatenate(z_chds), np.concatenate(z_txts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0fa9fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 100 / 62034 files\n",
      "processed 200 / 62034 files\n",
      "processed 300 / 62034 files\n",
      "processed 400 / 62034 files\n",
      "processed 500 / 62034 files\n",
      "processed 600 / 62034 files\n",
      "processed 700 / 62034 files\n",
      "processed 800 / 62034 files\n",
      "processed 900 / 62034 files\n",
      "processed 1000 / 62034 files\n",
      "processed 1100 / 62034 files\n",
      "processed 1200 / 62034 files\n",
      "processed 1300 / 62034 files\n",
      "processed 1400 / 62034 files\n",
      "processed 1500 / 62034 files\n",
      "processed 1600 / 62034 files\n",
      "processed 1700 / 62034 files\n",
      "processed 1800 / 62034 files\n",
      "processed 1900 / 62034 files\n",
      "processed 2000 / 62034 files\n",
      "processed 2100 / 62034 files\n",
      "processed 2200 / 62034 files\n",
      "processed 2300 / 62034 files\n",
      "processed 2400 / 62034 files\n",
      "processed 2500 / 62034 files\n",
      "processed 2600 / 62034 files\n",
      "processed 2700 / 62034 files\n",
      "processed 2800 / 62034 files\n",
      "processed 2900 / 62034 files\n",
      "processed 3000 / 62034 files\n",
      "processed 3100 / 62034 files\n",
      "processed 3200 / 62034 files\n",
      "processed 3300 / 62034 files\n",
      "processed 3400 / 62034 files\n",
      "processed 3500 / 62034 files\n",
      "processed 3600 / 62034 files\n",
      "processed 3700 / 62034 files\n",
      "processed 3800 / 62034 files\n",
      "processed 3900 / 62034 files\n",
      "processed 4000 / 62034 files\n",
      "processed 4100 / 62034 files\n",
      "processed 4200 / 62034 files\n",
      "processed 4300 / 62034 files\n",
      "processed 4400 / 62034 files\n",
      "processed 4500 / 62034 files\n",
      "processed 4600 / 62034 files\n",
      "processed 4700 / 62034 files\n",
      "processed 4800 / 62034 files\n",
      "processed 4900 / 62034 files\n",
      "processed 5000 / 62034 files\n",
      "processed 5100 / 62034 files\n",
      "processed 5200 / 62034 files\n",
      "processed 5300 / 62034 files\n",
      "processed 5400 / 62034 files\n",
      "processed 5500 / 62034 files\n",
      "processed 5600 / 62034 files\n",
      "processed 5700 / 62034 files\n",
      "processed 5800 / 62034 files\n",
      "processed 5900 / 62034 files\n",
      "processed 6000 / 62034 files\n",
      "processed 6100 / 62034 files\n",
      "processed 6200 / 62034 files\n",
      "processed 6300 / 62034 files\n",
      "processed 6400 / 62034 files\n",
      "processed 6500 / 62034 files\n",
      "processed 6600 / 62034 files\n",
      "processed 6700 / 62034 files\n",
      "processed 6800 / 62034 files\n",
      "processed 6900 / 62034 files\n",
      "processed 7000 / 62034 files\n",
      "processed 7100 / 62034 files\n",
      "processed 7200 / 62034 files\n",
      "processed 7300 / 62034 files\n",
      "processed 7400 / 62034 files\n",
      "processed 7500 / 62034 files\n",
      "processed 7600 / 62034 files\n",
      "processed 7700 / 62034 files\n",
      "processed 7800 / 62034 files\n",
      "processed 7900 / 62034 files\n",
      "processed 8000 / 62034 files\n",
      "processed 8100 / 62034 files\n",
      "processed 8200 / 62034 files\n",
      "processed 8300 / 62034 files\n",
      "processed 8400 / 62034 files\n",
      "processed 8500 / 62034 files\n",
      "processed 8600 / 62034 files\n",
      "processed 8700 / 62034 files\n",
      "processed 8800 / 62034 files\n",
      "processed 8900 / 62034 files\n",
      "processed 9000 / 62034 files\n",
      "processed 9100 / 62034 files\n",
      "processed 9200 / 62034 files\n",
      "processed 9300 / 62034 files\n",
      "processed 9400 / 62034 files\n",
      "processed 9500 / 62034 files\n",
      "processed 9600 / 62034 files\n",
      "processed 9700 / 62034 files\n",
      "processed 9800 / 62034 files\n",
      "processed 9900 / 62034 files\n",
      "processed 10000 / 62034 files\n",
      "processed 10100 / 62034 files\n",
      "processed 10200 / 62034 files\n",
      "processed 10300 / 62034 files\n",
      "processed 10400 / 62034 files\n",
      "processed 10500 / 62034 files\n",
      "processed 10600 / 62034 files\n",
      "processed 10700 / 62034 files\n",
      "processed 10800 / 62034 files\n",
      "processed 10900 / 62034 files\n",
      "processed 11000 / 62034 files\n",
      "processed 11100 / 62034 files\n",
      "processed 11200 / 62034 files\n",
      "processed 11300 / 62034 files\n",
      "processed 11400 / 62034 files\n",
      "processed 11500 / 62034 files\n",
      "processed 11600 / 62034 files\n",
      "processed 11700 / 62034 files\n",
      "processed 11800 / 62034 files\n",
      "processed 11900 / 62034 files\n",
      "processed 12000 / 62034 files\n",
      "processed 12100 / 62034 files\n",
      "processed 12200 / 62034 files\n",
      "processed 12300 / 62034 files\n",
      "processed 12400 / 62034 files\n",
      "processed 12500 / 62034 files\n",
      "processed 12600 / 62034 files\n",
      "processed 12700 / 62034 files\n",
      "processed 12800 / 62034 files\n",
      "processed 12900 / 62034 files\n",
      "processed 13000 / 62034 files\n",
      "processed 13100 / 62034 files\n",
      "processed 13200 / 62034 files\n",
      "processed 13300 / 62034 files\n",
      "processed 13400 / 62034 files\n",
      "processed 13500 / 62034 files\n",
      "processed 13600 / 62034 files\n",
      "processed 13700 / 62034 files\n",
      "processed 13800 / 62034 files\n",
      "processed 13900 / 62034 files\n",
      "processed 14000 / 62034 files\n",
      "processed 14100 / 62034 files\n",
      "processed 14200 / 62034 files\n",
      "processed 14300 / 62034 files\n",
      "processed 14400 / 62034 files\n",
      "processed 14500 / 62034 files\n",
      "processed 14600 / 62034 files\n",
      "processed 14700 / 62034 files\n",
      "processed 14800 / 62034 files\n",
      "processed 14900 / 62034 files\n",
      "processed 15000 / 62034 files\n",
      "processed 15100 / 62034 files\n",
      "processed 15200 / 62034 files\n",
      "processed 15300 / 62034 files\n",
      "processed 15400 / 62034 files\n",
      "processed 15500 / 62034 files\n",
      "processed 15600 / 62034 files\n",
      "processed 15700 / 62034 files\n",
      "processed 15800 / 62034 files\n",
      "processed 15900 / 62034 files\n",
      "processed 16000 / 62034 files\n",
      "processed 16100 / 62034 files\n",
      "processed 16200 / 62034 files\n",
      "processed 16300 / 62034 files\n",
      "processed 16400 / 62034 files\n",
      "processed 16500 / 62034 files\n",
      "processed 16600 / 62034 files\n",
      "processed 16700 / 62034 files\n",
      "processed 16800 / 62034 files\n",
      "processed 16900 / 62034 files\n",
      "processed 17000 / 62034 files\n",
      "processed 17100 / 62034 files\n",
      "processed 17200 / 62034 files\n",
      "processed 17300 / 62034 files\n",
      "processed 17400 / 62034 files\n",
      "processed 17500 / 62034 files\n",
      "processed 17600 / 62034 files\n",
      "processed 17700 / 62034 files\n",
      "processed 17800 / 62034 files\n",
      "processed 17900 / 62034 files\n",
      "processed 18000 / 62034 files\n",
      "processed 18100 / 62034 files\n",
      "processed 18200 / 62034 files\n",
      "processed 18300 / 62034 files\n",
      "processed 18400 / 62034 files\n",
      "processed 18500 / 62034 files\n",
      "processed 18600 / 62034 files\n",
      "processed 18700 / 62034 files\n",
      "processed 18800 / 62034 files\n",
      "processed 18900 / 62034 files\n",
      "processed 19000 / 62034 files\n",
      "processed 19100 / 62034 files\n",
      "processed 19200 / 62034 files\n",
      "processed 19300 / 62034 files\n",
      "processed 19400 / 62034 files\n",
      "processed 19500 / 62034 files\n",
      "processed 19600 / 62034 files\n",
      "processed 19700 / 62034 files\n",
      "processed 19800 / 62034 files\n",
      "processed 19900 / 62034 files\n",
      "processed 20000 / 62034 files\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(feature_files), block_size):\n\u001b[1;32m      4\u001b[0m     block \u001b[38;5;241m=\u001b[39m feature_files[start:start \u001b[38;5;241m+\u001b[39m block_size]\n\u001b[0;32m----> 5\u001b[0m     z_chd, z_txt \u001b[38;5;241m=\u001b[39m \u001b[43mencode_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     out_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(latent_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatents_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstart\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39mblock_size\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     np\u001b[38;5;241m.\u001b[39msavez(out_path, z_chd\u001b[38;5;241m=\u001b[39mz_chd, z_txt\u001b[38;5;241m=\u001b[39mz_txt, files\u001b[38;5;241m=\u001b[39mblock)\n",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m, in \u001b[0;36mencode_block\u001b[0;34m(files)\u001b[0m\n\u001b[1;32m      9\u001b[0m pr \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(pr)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m z_chd \u001b[38;5;241m=\u001b[39m polydis_model\u001b[38;5;241m.\u001b[39mchd_encode(c)\n\u001b[0;32m---> 11\u001b[0m z_txt \u001b[38;5;241m=\u001b[39m \u001b[43mpolydis_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtxt_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m z_chds\u001b[38;5;241m.\u001b[39mappend(z_chd\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     13\u001b[0m z_txts\u001b[38;5;241m.\u001b[39mappend(z_txt\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m/workspace/vae-tuning-texutres/interface.py:38\u001b[0m, in \u001b[0;36mPolyDisVAE.txt_encode\u001b[0;34m(self, pr_mat, sample)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 38\u001b[0m     dist_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtxt_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpr_mat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     z_txt \u001b[38;5;241m=\u001b[39m dist_txt\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;28;01mif\u001b[39;00m sample \u001b[38;5;28;01melse\u001b[39;00m dist_txt\u001b[38;5;241m.\u001b[39mmean\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m z_txt\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/vae-tuning-texutres/dl_modules/texture_encoder.py:29\u001b[0m, in \u001b[0;36mTextureEncoder.forward\u001b[0;34m(self, pr)\u001b[0m\n\u001b[1;32m     27\u001b[0m bs \u001b[38;5;241m=\u001b[39m pr\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m pr \u001b[38;5;241m=\u001b[39m pr\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m pr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(bs, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m pr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(pr))  \u001b[38;5;66;03m# (bs, 8, emb_size)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m pr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(pr)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# process files in blocks and store latent codes\n",
    "block_size = 100\n",
    "for start in range(0, len(feature_files), block_size):\n",
    "    block = feature_files[start:start + block_size]\n",
    "    z_chd, z_txt = encode_block(block)\n",
    "    out_path = os.path.join(latent_dir, f'latents_{start//block_size:03d}.npz')\n",
    "    np.savez(out_path, z_chd=z_chd, z_txt=z_txt, files=block)\n",
    "    print(f'processed {start + len(block)} / {len(feature_files)} files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4588cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of reading saved latent representations later\n",
    "latent = np.load(os.path.join(latent_dir, 'latents_000.npz'))\n",
    "z_chd = latent['z_chd']\n",
    "z_txt = latent['z_txt']\n",
    "file_names = latent['files']\n",
    "print(z_chd.shape, z_txt.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
