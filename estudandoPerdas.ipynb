{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66f2a63-182b-4ceb-8353-fa2d9b5b1d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c36c5b9-d415-4f9b-b5cc-fd001f14b0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./base_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce1d8592-e7df-4c6a-bfac-8596d5663841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_model.dataset import wrap_dataset\n",
    "from base_model.model import DisentangleVAE\n",
    "from interface import PolyDisVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94dd592-6636-4725-ad99-9b8c03258c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c99d5063-5358-469e-8648-dd0761e73e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample(path):\n",
    "    dataset = wrap_dataset([path], [0], shift_low=0, shift_high=0,\n",
    "                           num_bar=2, contain_chord=True)\n",
    "    mel, prs, pr_mat, x, c, dt_x = dataset[0]\n",
    "    return x, c, pr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce931fda-a1d1-4490-94dc-f1a5276a91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tensors(x, c, pr_mat, device):\n",
    "    x = torch.tensor(x).long().unsqueeze(0).to(device)\n",
    "    c = torch.tensor(c).float().unsqueeze(0).to(device)\n",
    "    pr_mat = torch.tensor(pr_mat).float().unsqueeze(0).to(device)\n",
    "    return x, c, pr_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8133652e-6bec-4e6d-b54a-25a537f3568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(device):\n",
    "    interface = PolyDisVAE.init_model(device=device)\n",
    "    interface.load_model('./model_param/polydis-v1.pt')\n",
    "    model = DisentangleVAE('disvae', device,\n",
    "                           interface.chd_encoder,\n",
    "                           interface.txt_encoder,\n",
    "                           interface.pnotree_decoder,\n",
    "                           interface.chd_decoder)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2466608-9be4-4e19-823a-dbb9571265f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/vae-tuning-texutres/interface.py:95: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dic = torch.load(model_path, map_location=self.device)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DisentangleVAE(\n",
       "  (chd_encoder): ChordEncoder(\n",
       "    (gru): GRU(36, 1024, batch_first=True, bidirectional=True)\n",
       "    (linear_mu): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (linear_var): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       "  (rhy_encoder): TextureEncoder(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(1, 10, kernel_size=(4, 12), stride=(4, 1))\n",
       "      (1): ReLU()\n",
       "      (2): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (fc1): Linear(in_features=290, out_features=1000, bias=True)\n",
       "    (fc2): Linear(in_features=1000, out_features=256, bias=True)\n",
       "    (gru): GRU(256, 1024, batch_first=True, bidirectional=True)\n",
       "    (linear_mu): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (linear_var): Linear(in_features=2048, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): PianoTreeDecoder(\n",
       "    (note_embedding): Linear(in_features=135, out_features=128, bias=True)\n",
       "    (z2dec_hid_linear): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (z2dec_in_linear): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (dec_notes_emb_gru): GRU(128, 128, batch_first=True, bidirectional=True)\n",
       "    (dec_time_gru): GRU(512, 1024, batch_first=True)\n",
       "    (dec_time_to_notes_hid): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (dec_notes_gru): GRU(1152, 512, batch_first=True)\n",
       "    (pitch_out_linear): Linear(in_features=512, out_features=130, bias=True)\n",
       "    (dec_dur_gru): GRU(5, 64, batch_first=True)\n",
       "    (dur_hid_linear): Linear(in_features=642, out_features=64, bias=True)\n",
       "    (dur_out_linear): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       "  (chd_decoder): ChordDecoder(\n",
       "    (z2dec_hid): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (z2dec_in): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (gru): GRU(292, 512, batch_first=True)\n",
       "    (root_out): Linear(in_features=512, out_features=12, bias=True)\n",
       "    (chroma_out): Linear(in_features=512, out_features=24, bias=True)\n",
       "    (bass_out): Linear(in_features=512, out_features=12, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e59aae-5362-40a1-9a34-33a09c0220f7",
   "metadata": {},
   "source": [
    "## run function\n",
    "\n",
    "```\n",
    " def run(self, x, c, pr_mat, tfr1, tfr2, tfr3, confuse=True):\n",
    "        embedded_x, lengths = self.decoder.emb_x(x)\n",
    "        # cc = self.get_chroma(pr_mat)\n",
    "        dist_chd = self.chd_encoder(c)\n",
    "        # pr_mat = self.confuse_prmat(pr_mat)\n",
    "        dist_rhy = self.rhy_encoder(pr_mat)\n",
    "        z_chd, z_rhy = get_zs_from_dists([dist_chd, dist_rhy], True)\n",
    "        dec_z = torch.cat([z_chd, z_rhy], dim=-1)\n",
    "        pitch_outs, dur_outs = self.decoder(dec_z, False, embedded_x,\n",
    "                                            lengths, tfr1, tfr2)\n",
    "        recon_root, recon_chroma, recon_bass = self.chd_decoder(z_chd, False,\n",
    "                                                                tfr3, c)\n",
    "        return pitch_outs, dur_outs, dist_chd, dist_rhy, recon_root, \\\n",
    "            recon_chroma, recon_bass\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b7bf837-a4e1-41d0-990b-b53191768099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pra ver como est√° sendo calculado o debug_run\n",
    "\n",
    "def debug_run(model, x, c, pr_mat):\n",
    "    names = [\n",
    "        'recon_pitch', 'recon_dur', 'dist_chd', 'dist_rhy',\n",
    "        'recon_root', 'recon_chroma', 'recon_bass'\n",
    "    ]\n",
    "    outputs = model.run(x, c, pr_mat, 0., 0., 0.)\n",
    "    print('--- run() outputs ---')\n",
    "    for n, o in zip(names, outputs):\n",
    "        if isinstance(o, torch.distributions.Distribution):\n",
    "            print(f'{n}: mean {tuple(o.mean.shape)}, std {tuple(o.stddev.shape)}')\n",
    "        else:\n",
    "            print(f'{n}: {tuple(o.shape)}')\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14ed2b5-f1e1-439f-9914-d04a60fc6003",
   "metadata": {},
   "source": [
    "## loss function\n",
    "\n",
    "```\n",
    "def loss_function(self, x, c, recon_pitch, recon_dur, dist_chd,\n",
    "                      dist_rhy, recon_root, recon_chroma, recon_bass,\n",
    "                      beta, weights, weighted_dur=False):\n",
    "        recon_loss, pl, dl = self.decoder.recon_loss(x, recon_pitch, recon_dur,\n",
    "                                                     weights, weighted_dur)\n",
    "        kl_loss, kl_chd, kl_rhy = self.kl_loss(dist_chd, dist_rhy)\n",
    "        chord_loss, root, chroma, bass = self.chord_loss(c, recon_root,\n",
    "                                                         recon_chroma,\n",
    "                                                         recon_bass)\n",
    "        loss = recon_loss + beta * kl_loss + chord_loss\n",
    "        return loss, recon_loss, pl, dl, kl_loss, kl_chd, kl_rhy, chord_loss, \\\n",
    "               root, chroma, bass\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6fe95ee-270a-4ada-a2f2-cfbb14548677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pra ver como funciona a loss function\n",
    "\n",
    "def debug_loss_function(model, x, c, run_outputs):\n",
    "    labels = [\n",
    "        'total_loss', 'recon_loss', 'pitch_loss', 'dur_loss',\n",
    "        'kl_loss', 'kl_chd', 'kl_rhy',\n",
    "        'chord_loss', 'root_loss', 'chroma_loss', 'bass_loss'\n",
    "    ]\n",
    "    loss_values = model.loss_function(x, c, *run_outputs, beta=0.1, weights=(1, 0.5))\n",
    "    print('--- loss_function() breakdown ---')\n",
    "    for label, val in zip(labels, loss_values):\n",
    "        if torch.is_tensor(val):\n",
    "            if val.dim() == 0:\n",
    "                print(f'{label}: {val.item()}')\n",
    "            else:\n",
    "                print(f'{label}: {tuple(val.shape)}')\n",
    "        else:\n",
    "            print(f'{label}: {val}')\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcfe0309-0f60-42f8-9913-6fb8f15e4a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss():\n",
    "    data_path = './dataSet/POP09-PIANOROLL-4-bin-quantization/001.npz'\n",
    "    model = load_model(device=device)\n",
    "    x, c, pr_mat = load_sample(data_path)\n",
    "    x, c, pr_mat = prepare_tensors(x, c, pr_mat, model.device)\n",
    "\n",
    "    loss, *_ = model.loss(x, c, pr_mat)\n",
    "    print('Loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52b70ad6-c1fe-4c97-b644-ffbc7f965f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3808215856552124\n"
     ]
    }
   ],
   "source": [
    "calc_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5785b757-851e-49c5-9d3e-7ef895177e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from compute_single_loss import main as compute_single_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaeda25d-3a03-48b4-97fe-934c575df58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4973600208759308\n"
     ]
    }
   ],
   "source": [
    "compute_single_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0caa2493-ddf2-419c-80c8-1d7e07436652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_debug():\n",
    "    data_path = './dataSet/POP09-PIANOROLL-4-bin-quantization/001.npz'\n",
    "    model = load_model(device=None)\n",
    "    x, c, pr_mat = load_sample(data_path)\n",
    "    x, c, pr_mat = prepare_tensors(x, c, pr_mat, model.device)\n",
    "\n",
    "    run_outs = debug_run(model, x, c, pr_mat)\n",
    "    debug_loss_function(model, x, c, run_outs)\n",
    "\n",
    "    loss, *_ = model.loss(x, c, pr_mat)\n",
    "    print('Final loss from model.loss():', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05bb62cc-9cf3-4a5c-8cf3-2eb12de8bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- run() outputs ---\n",
      "recon_pitch: (1, 32, 15, 130)\n",
      "recon_dur: (1, 32, 15, 5, 2)\n",
      "dist_chd: mean (1, 256), std (1, 256)\n",
      "dist_rhy: mean (1, 256), std (1, 256)\n",
      "recon_root: (1, 8, 12)\n",
      "recon_chroma: (1, 8, 12, 2)\n",
      "recon_bass: (1, 8, 12)\n",
      "--- loss_function() breakdown ---\n",
      "total_loss: 0.39179641008377075\n",
      "recon_loss: 0.24111223220825195\n",
      "pitch_loss: 0.1323319375514984\n",
      "dur_loss: 0.2175605744123459\n",
      "kl_loss: 1.2786529064178467\n",
      "kl_chd: 0.3809277415275574\n",
      "kl_rhy: 0.8977251648902893\n",
      "chord_loss: 0.02281886339187622\n",
      "root_loss: 0.0028574406169354916\n",
      "chroma_loss: 0.01977548561990261\n",
      "bass_loss: 0.00018593735876493156\n",
      "Final loss from model.loss(): 0.3384990692138672\n"
     ]
    }
   ],
   "source": [
    "calc_loss_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67245ff4-6233-4c14-bd0e-83814d85f80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
